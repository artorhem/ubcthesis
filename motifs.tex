\chapter{section}{Motifs in TEE Research}
\label{motifs}
We now turn our attention to inspecting the usecases that TEE based
applications have been designed for in prior work. Threat models are based
on the underlying usecases, and we investigate each with the intention of
assessing their applicability for unmodified applications. 
    
\begin{subsection}{Verifying User Actions}
This is perhaps the most common usecase for trusted execution and is widely
employed on modern mobile devices. The crux of the problem is this:
\emph{How can an application verify if the user actually requested, and
wishes to perform the requested action?} \\
The application needs to be shielded from other - potentially malicious -
applications, users, and the Operating System. In this multi-user,
multi-process environment running on a potentially compromised operating
system, the "good" application's memory and state can be arbitrarily
manipulated, forcing it to perform actions unintended by the actual user. \\
Verifying the user's identity can be addressed with two-factor
authentication(TFA), but it is a one-time check after which there can be no
guarantees  made about the applications state. A malicious application might
attack after the two-factor authentication has been completed. Besides, TFA
based schemes are notoriously hard to use\cite{herley2011research}. 

If TEEs are employed, this becomes significantly easeir to solve. The
identity of the user can be resolved using a trusted biometric scanner that
operates from within the TEE. The users intention can be verified with the
use of Trusted UI rendering that asks the user to verify that she did indeed
initiate that action. This is now a standard feature on
Android\cite{androiddevelopersblog_2018}, and is used by applications such
as Duo Security, Nok Nok Labs, and ProxToMe for user authentication and
Insulet Corporation and Bigfoot Biomedical for medical device
control\cite{androiddevelopersblog_2018}. 

This threat model requires an application to use the interface provided by
the TEE sequestered authentication service and, depending on the level of
support provided by the TEE and untrusted operating system, the application
might have to implement it's own TEE-based authentication
scheme\cite{liu2014veriui}. 

\end{subsection}

\begin{subsection}{Protecting Copyright Data from User}
This is the classic Digital Rights Management(DRM) problem. An application
must protect copyrighted information from the user that it is contractually
obligated to service. DRM is used to prevent accidental leakage of
copyrighted data to the user, and ensuring that the data is only used in
ways that the data owner explicitly permits. Successfully achieving DRM on
an untrusted Operating System is not possible, and the most common way to
circumvent this limitation is through the use of TEEs to handle the media
stream decryption and display.  This assumes that the TEE has a secure I/O
mechanism  and has a mechanism to ensure exclusive access to the
peripherals.There are a lot of DRM solutions being used in the industry such
as Microsoft PlayReady\cite{microsoftplayready} and Widevine
\cite{widevine}. 

A more general formulation of the DRM problem is the scenario where an
application wishes to hide some sensitive data from the user. One way to
ensure safety of copyright information is to control the device peripherals
to ensure that the user is not able to transmit any information. Some recent
research \cite{restrictedspaces, SeCloak} in this space has focussed on the
slightly orthogonal problem of ensuring that in copyright sensitive
situations, an application or the user can leverage TEEs to control the
peripherals. The Restricted Spaces\cite{restrictedspaces} work presents
mechanism  where the host can analyse and regulate a guests TrustZone
devices. This is done by reading and modifying the guest device's normal
world state from TrustZone and nullifying the peripheral device drivers in
accordance to the host's security policy. SeCloak\cite{SeCloak} achieves
this same objective by labeling the memory regions that belong to peripheral
devices as sensitive and trapping any normal world accesses to the secure
world. %This requires the peripheral devices to
%carry some notion of the security level at which they are being used. 

Both these works assume that the device hardware is not malicious and that a
secure boot mechanism exists to reliably set up the secure world. 
%SeCloak further requires a signed device tree that enumerates all
% information about the peripherals present on the board.
Neither work places any trust in any software running in the normal world.
This area of research requires much support from the TEE ecosystem to
ensure that the proper secure IO channels and peripheral control mechanisms
exist inside the TEE. \textbf{An unmodified application is unlikely to
benefit from the TEE, unless there is a system call interception from the
normal world that is able to discern copyright sensitive file accesses and
route them to the TEE.}

\end{subsection}
    
\begin{subsection}{Protecting Application Secrets}
Applications have secrets - user data, encryption keys, proprietary
algorithms - that must be kept safe from the untrusted operating system and
the user. In the presence of an untrusted operating system that cannot
protect the application from attack by a rogue user or process, these
secrets can only be protected using a TEE or offloading that computation to
another trusted device (ex: pushing the secure computation to the cloud). 

In the presence of a TEE, this problem can be targeted by decomposing the
application into trusted and untrusted parts~\cite{TLR,Proxos}. The trusted
parts of the application - the secure classes and interfaces - are run
inside the TEE. The untrusted  parts rely on the results of the secure
computation done in the TEE, not the data being processed to get to those
results. An attacker that has unfettered access to the untrusted OS can only
access the normal world interfaces, but not the actual code and data that's
held in the TEE. While TLR~\cite{TLR} uses TrustZone to host a small .NET
managed runtime to execute the secure concrete classes, Proxos~\cite{Proxos}
uses the notion of a secure VM that's hosted on the same hypervisor as the
commodity untrusted OS. On the other hand, this is application partitioning
scheme is central to the Intel SGX programming model. \emph{All}
applications written using the Intel SGX Software Development Kit requires
that the application be split into trusted and untrusted parts.

The requirement to partition applications increases the burden on the
developer to identify not only identify the secure parts of his applciation,
but also learning to use the TEE vendor's API. To lessen the burden from app
developers, Truz-Droid\cite{ying18truzdroid} integrates the TEE with the
Android OS and provides ready to use elements that can be incorporated into
the app directly. There has also been some work in the Software Engineering
domain to automatically identify the secure parts of the application and
split the application into the secure and unsecure parts. Glamdring
\cite{lind2017glamdring} does this for SGX based applications and the work
by Rubinov et. al.\cite{rubinov2016automated} does the same for Android
applications and partitions them for Sierra TEE\cite{sierratee}. \textbf{The
automated partitioning scheme is very promising for using with unmodified
applications, assuming the TEE is structured in a way that allows for such
decomposition to occur.}

\subsection{Protecting User Secrets}
While using an application, the user might wish to store some secrets like
credit card information, passwords, etc. in their browsers. A web browser
allows for arbitrary code execution in a sandboxed environment, and this
makes these saved secrets particularly vulnerable to attacks. Running the
entire unmodified browser in the TEE therefore, is a poor design choice.
The Fidelius \cite{Fidelius_SP2018} project that aims to protect the user's
interaction with the browser by sequestering the code that handles sensitive
information in an SGX enclave and providing trusted IO path to the user to
interact with the secure web enclave. The web enclave is used to render the
Secure HTML forms found in the DOM tree and handle scripts that deal with
the user's information. 

This work assumes an interesting threat model: there is no trust placed in
the normal world. More importantly, the unsafe parts of the application
(extensions and scripts in the case of a browser) can compromise the other
innocuous parts of the application. They assume that the peripheral devices
are trusted, and there is a trusted IO path. They establish the trust
between the peripheral device and the enclave using an attestation/key
exchange protocol. This is similar to the split-interface design since it
requires the secure functionality of the browser to be extracted into a
secure enclave. Fidelius provides to the programmer an interface to protect
security-critical components of his application. 
    
  
\subsection{Complete Application Isolation}
There has been a lot of reseach into protecting applications by completely
isolating them from the untrusted Rich Operating System through the use of
either trusted hypervisors \cite{hofmann2013inktag,SP3,chen2008overshadow},
compiler instrumentation to isolate the applications
\cite{criswell2014virtual} or the use of TEEs
\cite{baumann2015shielding,guan17trustshadow}. Recent work
\cite{TsaiGraphene2014, tsai2017graphene} has also investigated the use of
TEE based library OS's to isolate the applications. 

This research into protecting unmodified applications has gained traction
because splitting interfaces of an application is usually a difficult task
that is hard to get right. Instead, it might be easier to isolate complete
applications using the TEE or the virtual machine monitor. The threat model
here is that the attacker has compromised the operating system and can
execute arbitrary code and can interfere with the memory and register state
of any process. Any data that is needed by the application being sequestered
is either made available at initialization, or it is assumed that the TEE
has I/O capability. TrustZone does not impose any theoretical limitations on
this, the actual filesystem support often relies on the REE OS
\cite{optee_filesystem}. On the other hand, the I/O support in SGX is fairly
limited. In the Graphene project\cite{TsaiGraphene2014, tsai2017graphene},
the payload manifest contains a list of all the files which should be made
available to the payload running within the SGX enclave. This includes the
input and output files, which are automatically encrypted and
integrity-protected by a corresponding user-side tool, in such a way that
only the proper payload in a valid SGX enclave can read and write them.
\textbf{This significantly limits the usability of such full-application
isolation schemes, but overall, this isolation scheme is very promising for
securing unmodified applications.}
    
   
\end{subsection}

\begin{subsection}{Machine Learning Asset Protection}
With the advent of decentralized machine learning applications, there has
been a renewed interest in the application of TEEs to protect the sensitive
code and data that power these prediction systems. There are many targets
that need protection in a Machine Learning environment, for example:
\begin{itemize}
    \item \textbf{Proprietary Models:} The contest organizer sends private
    test data to your model and gets verifiable report of accuracy. Your
    model stays safe until the organizer decides to purchase it. Other
    participants canâ€˜t cheat by training on test data.
    \item \textbf{Federated Learning:} user's personal data remains
    protected from other untrusted peers in multi-party computation. The
    gradient updates also need protection to ensure a peer doesn't hamper
    the training process.
    \item \textbf{Private MLaaS}: The user data needs to be protected from
    the untrusted ML-as-a-Service platform.
\end{itemize}

All ML related research in the TEE space assumes a similar threat model. The
user data once acquired, is not usually considered a protected asset as long
as it is used for training on the same device as the one on which it
originated (An example would be SwiftKey\cite{swiftkey_support}). A
malicious app or user might inject adversarial inputs or might tamper with
the final gradients being emitted by a peer in a multiparty computation
which leads to model poisoning. Since most ML training algoriths are
resource heavy and trained on a cloud platform, most research in this space
focusses on protections from the Cloud Platform
\cite{ohrimenko2016oblivious,ryoan}. 

In the work by Ohrimenko et.al\cite{ohrimenko2016oblivious}, a common
computation is done on datasets sourced from multiple mutually distrusting
parties. The neutral party in this work is the SGX enclave running in the
cloud, and the adversary to any one peer is the cloud administrator and the
other peers. Each peer provides the encrypted data and the associated keys
to the cloud  provider, and this data is decrypted only in the SGX enclave
that runs the agreed upon ML algorithm. The enclave processes teh aggregate
datasets and emits an encrypted ML model. 

Ryoan\cite{ryoan} goes a step further in its threat assumptions: multiple,
mutually distrustful parties are involved in data-processing services, and
neither are trusted by the data owner to keep the data secret. Neither the
application nor the infrastructure is in the control of the user, and the
malicious ML service provider may collude with the infrastructre provider to
steal user's data through covert channels.


\end{subsection}
    
    
\subsection{What Applications Need}


At the time of creating a secure application, the developer needs to make
some assumptions about the threat models in will operate. Threat models need
to be defined before the application is being developed in-order to make any
reasonable guarantees about the state that remains protected in the course
of normal operation. Seen another way, this means that for a given threat
model, only a few applications are a reasonable fit. Retrofitting
applications to a pre-existing threat model is hacky and difficult and does
not lead to satisfactory outcomes.

If we analyse the example applications presented in the body of research we
have discussed in section \ref{motifs}, we can understand that there is a
% very narrow class of applications that can benefit from TEEs. Table
% \ref{fig:table} presents the example applications for each work we have
% discussed so far. We also present the hardware requirements each of those
% applications need to fully utilize TEEs.
